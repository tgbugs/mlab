add a way to track versions by commit hash
find a way to integrate all the controllers without using the stupid dicts >_< so we can persist stuff without having to jump through all the hoops, maybe just have the classes also inherit from datFuncs?
add properties to datafiles for keeping track of mcc state etc
results tables or fields or something
move stuff to analysis folder/module
#make intersperse the distances with the spot over the cell
#fix minV maxV
#ADD NOTES TO DATAFILES AND EXPERIMENTS!!!
change ':' command so that it looks up function names in a dict?
add a way to mark harpstrings!
add to the datafile record a HSTORE or something? that can track all the settings used on the multiclamp or even just put it in an array or add properties to datafiles?
#add a way to access note datetime, via _notes
#add a key to turn off the motors!
#automatically get esp position when a datafile is recorded!

-4. see mapper_config.html for ideas about versioning counters etc
-3. a better way to make dataios is to use a DECORATOR that decorates a DO function and sticks them all in a dict! the only issue is that we would always import EVERY dataio instead of just some of them... still would be nice to just reference them by name and have the dict deal with it, probably preferable
	a) this also suggests that there needs to be a __specific__ way to look for dataios for steps, or maybe... no, just import the dataio file to steps file and look stuff up via locals?
-2. dissociate numbers in protocols from sanity checks and actual metadata, there are a couple of possible ways to do this
-1. need to make simulated datasources/protocols to test stuff
0. what if we treat File as a datasource? well, then we loose the temporal correlation... BUT if we could just bring that along, then the code for decoding the file wouldn't be analysis it would be like a controller... yes, try to implement this, it could be much more consistent and so long as we have the datetime all synced up and stuff like that... BUT BUT BUT then we need some unti (sub experiment? to hold all the associated data...)
1. Finish cleaning up the rest of the comments
2. Break my own classes out into their own files/folders
3. Finish the steps api, keeping corrispondence with database tables
4. convert the TODO list into something that is actually readable
5. Users and different database vs different schema or user defined schema so we can share common tables such as the units, and people and users
6. neo, and quantities or pint or something
7. datetime.now as default has HUGE problems with clock sync
8. can we generalize dataobjects in a way that simplifies things and makes analysis easier? yes, see data.py DataInterface, start w/ handling my own data and neo's data and build in imaging
9. how to fix alignment between metadata without grouping it or just group it and be done? tensor of datasources that will be called to produce the tuple/matrix/whatever
10. check to see where I actually need primaryjoin in relationships and where I can just use the foreign_keys option on relaitonship http://docs.sqlalchemy.org/en/rel_0_8/orm/relationships.html#relationships-api
11. relationships, change remote_side to remote() annotation inside of primaryjoin
12. import logging
13. make args based interfaces for regular use that don't require typing the kwargs every time
14. automatically back up saved datafiles between subjects, OR have a back up step
15. epochs/intervals are another things that I kinda might want to deal with, very useful for the pharmacological bit...? technically they go in the metadata as a bool, the question is how to represent them... well bools should probably just go into the experiment timeline, how that fits with the timeline for timeserries data I will need to think about...
16. session_maker that automatically attaches table logic events

----------main.py
#TODO repeated func calls: itertools repeatfunc starmap
#FIXME many of the options only apply if postgres is used...
__ from IPython import embed #TODO ipython

#Base file for creating the tables that I will use to store all my (meta)data

#TODO use postgres search_path to control the user so that we can share basic things such as constants and strain information, definately need to audit some of those changes... audit table...

#FIXME holy shit problems with using datetime.now as the default for DateTime!

#TODO when thinking about staging this stuff I need a safe way to hold data incase my access to the db goes down, like pickling something or the like? ideally this shouldn't happen but better safe than sorry

#TODO conform to MINI, NIF ontologies?, or odML terminiologies?

#TODO
### Create an IsLoggable class or the like to manage logging changes to fields
#see: http://stackoverflow.com/questions/141612/database-structure-to-track-change-history
#TODO transaction log will have a first entry for...
#internal doccumentation of the creation date may not be needed if I have refs to transactions

#TODO transfer logs for mice can now be done and incorporated directly with the system for weening etc

__ #TODO reimplement notes so that they can apply to multiple things like I do with classDOB, but check the overhead, join inheritance might work
__ #make sure to set the 'existing table' option or something?

#TODO neo io for dealing with abf files, but that comes later
#OBJECTIVE raw data format agnostic, this database does not house the raw data, it houses the assumptions and the results and POINTS to the analysis code and the raw data
#if needs be the code used to analyize the data can be stored and any updates/diffs can be added to track how numbers were produced
#this means that this database stays flexible in terms of what kinds of experiments it can handle
#it also maximizes poratbility between different backend databases

----------data.py
one thing way up on the list is allowing for multi dimensional or array data under the same type of heading as datadatsource and combining it in to a single thing all of which will have units etc pulled from datafiles or the like, could just blob it for sqlite...
#TODO how to persist protocols may not even need this... though there are worse ideas than storing versions of the python code in the database, it might just be better to store the git commit and filename
#FIXME TODO DataFiles have an associated experiment, doesn't metadata ALSO need an experiment, or can we associate MD to exp some other way? that is the scope is the experiment, disticnt from actual experiment metadata
#FIXME TODO this can just be called 'DataSource' because it can reference array or scalar data
#wheter I want a flag for marking scalar or array is another question, also the segments/as from neo...
#FIXME TODO if the server is not local then file:/// only has meaning for the computer that the data was originally stored on and that has to match :/
#TODO quantities integration
#FIXME CRITICAL MUST implement something similar to the record keeping for MDS
#because the hardware/swc association can and will change
#the persistence for the Subject needs to come from the history table that gets recorded on a per experiment basis, this would allow a subject to have a single hardware_id and resolve the convlict of having to figure out which piece of hardware to use for analysis if for example, 2 different extracellular probes were used on the same animal on different days and inserted into the opposite locations
#TODO request.urlopen works perfectly for filesystem stuff
#FIXME TODO DataFile is currently a standin for a 'protocol' which is what we really want so that data can flexibly be stored inside or outside the program this will be the "unit of data"?? the "segment" or set of segments... basically the neoio thing that is generated from a single protocol file and may in point of fact have different metadata for each sub segment, but that at least has it in a consistent and preictable way
#FIXME something is a bit off with HDFS
#TODO InDatabaseData need something more flexible than metadata (amazingly) that can hold
#stuff like calibration data not stored elsewhere?? also if I ever
#transition away from external datafiles or if I want to use neoio
#immediately to convert abf files
#also, integration with neo's structure migth be rather important
#can probably just map directly on to their class structure...
#TODO, if we are going to store credentials in a database then the db needs to pass sec tests, but it is probably better than trying to secure them in a separate file, BUT we will unify all our secure credentials management with the same system
#TODO google docs access does not go here because those could be writeable too
#these should point to more or less static things outside the program, every revision should add a new datafile for consistency, store the diffs?
#how to constrain/track files so they don't get lost??
#well, it is pretty simple you force the user to add them, this prevents all kinds of problems down the road
#and the constraint will be populated by the DataPath table, if I have 10,000 datafiles though, that could become a NASTY change
#ideally we want this to be dynamic so that the DataPath can change and all the DataFile entries will learn about it
#it might just be better to do it by hand so UPDATE doesn't swamp everything
#TODO next problem: when do we actually CREATE the DataFile and how to we get the number right even if we discard the trial? well, we DONT discard the file, we just keep it, but we need to gracefully deal with deletions/renumbering so that if something goes wrong it will alert to user
#RESPONSE: this record cannot be created until the file itself exists
#FIXME datafiles have substructure that requires more than one datasource ;_;
#although, the easiest way to fix that is to just change this to allow for an arbitrary number of channels to be saved per datafile and link the datasources to those?
#maybe base it on datafile type??? or configuration... but that is going to change for every fucking thing...
#that stuff goes in the metadata, datasource here just means 'collection software' fucking conflation

----------experiment.py    
sub experiments that keep track of what was held constant at their level? this is related to what to do about projects

#FIXME generation experiment!???! basically fix the ven diagram problem with gen subjects and data subjects
#TODO what/who is the REAL subject of experiment data? the procedure? the experimenter? the generated subjects? probably it is actually stuff that is used as a sanity check against the protocol... hrm... HRM
#TODO logical relationships between experiments could be manifest here, but THAT is a project for another day
#TODO addition of new data does not trigger version bump but any changes to existing entries should

#TODO in theory what we want is for experiments to have a m-m on itself to convey logical connections, in which case a mating record is just an experiment.... HRM, think on this... we certainly want the m-m for logical depenece I think

#why experiment type instead of inheritance? because I don't want to force users to learn sqlalchemy, furthermore, doccumenting experiments in code defeats the purpose of saving all of this stuff in a database from a record keeping point of view

#TODO on a per-experiment basis I need bindings between hardware and metadatasources
#TODO AND I need a binding between datafiles/datafile channels and subjects
#in biology there are expeirments that generate data, or data and subjects, if they generate only subjects then they should probably have some data to go along with them or the science might be bad

#TODO single table inheritance for experiments too to and all the nifty functions??? YES TODO
#TODO enforcing type that way and then ste works pretty well... ExperimentType instances could become factories... that might be VERY handy... well, not really, because what we need are the fucntions, work on it...

#TODO: figure out the base case for experiments (ie which subjects) for
#TODO this does not need to be done right now, just make sure it will integrate easily
#do we keep weight's here or somehwere else, is there any other reason why a 'normal' mouse would need to be weighed? sure the mouse HAS a weight, but does that mean that the mouse table should be where we keep it? it changes too
#same argument applies to sex and how to deal with changes to that, and whether it is even worth noting
#somehow this reminds me that when weaning mice need to make sure that their cages get matched up properly... well, that's the users job
#TODO lol the way this is set up now these classes should actually proabaly DEFINE metadata records at least for simple things like this where the only associated object is a mouse which by default experiment asssociates with, maybe I SHOULD move the mouse_id to class MouseExperiment?!?!?!

 #TODO project_id if i keep track of these at the level of experiment type then everything becomes problematic if I want to change the project or experiment or reuse stuff, but if I want to record WHO did the experiment as an experimental variable...
    #also the being of the experiment type is not defined by which project it is for but project_id is a nice  way to tie everything together...
    #maybe metadata for an experiment is who did it?


----------analysis.py
hybrid attributes could be REALLY REALLY handy for computing stuff on the fly... like... results
the analysis object can hold references to all the objects it needs and then bam hybrid_property
obviously a bit trickier for datafiles

----------genetics.py
#NOT subjects because they are actually the exact opposite, genes are universals with many, many instantiations, the complete object of subjects
#you can't study a gene as if it is an organism Dawkins, because the notion that genes exist in the way we idealize them is completely wrong, the context of the gene is different for pretty much every cell (type if you must be a bit stodgy about initial conditions), I cant even draw a good analogy at the moment to some higher level phenomenon
#incidentlaly you *could* study a single gene if you could go in to a single cell and look at how frequently that section of dna was transcribed but if you did that you would pretty soon realize that the causal story is so much more complicated that the central dogma starts to look pretty silly, just think of all the intervening steps and interactions between the product of a dna squence in a single cell and the phenotype of an organism, in fact, that cell will usually die long before it alone could impact the phenotype of the organism...
#something about information does mislead us, you're right Dan...

----------inventory.py
how to construct recipes and versions of recipes from queries against ingredients
#TODO could just make this a hardware table and maybe CHECK that the type matches?
#then just have another table for any specifics on that, could do the same for the reagents, since most of them are going to have links to urls and msdses or whatever the fuck

    #FIXME the current state of this table (Hardware) reveals the conflict between building a cooperative tool that keeps references to all the other outside data and one the keeps all the data inside
    #ACTUALLY the above is false, the distinction is merely whether we go get the data before we add a record to the database or when we retrieve the record to do something with it
    #I can't predict everything that this could be used for or the format, but I can predict that I will want to know the relation between things but the exact computations may be different, in which case we would want single table inheritance for processing stuff on retrieval or something like that, functions to call on specific types of data maybe that new 3.4 feature could help

    #TODO I MUST have a way to track changes in the hardware parent so that datafiles will have the state when THEY were recorded...

